{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-output":false},"cell_type":"code","source":"! pip install -U tokenizer","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"! pip install tensorflow==1.15","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tokenizers","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create Vocabulary from the corpus\nbwpt = tokenizers.BertWordPieceTokenizer(\n    vocab_file=None, # We want to build a vocabulary\n    add_special_tokens=True,\n    unk_token='[UNK]',\n    sep_token='[SEP]',\n    cls_token='[CLS]',\n    clean_text=True,\n    handle_chinese_chars=True, # We have some chinese characters in corpus\n    strip_accents=True,\n    lowercase=True, # Coz we will use BERT Based uncased not cased.\n    wordpieces_prefix='##'\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#  ! split -l 250000 hi_dedup.txt hindi_\n# Spilt the files using Bash command to train faster\n# import glob\n# file_list = glob.glob(\"../hindi_*\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bwpt.train(\n    files=[\"../input/hindi-oscar-corpus/hi_dedup_1000.txt\"],\n    vocab_size=30000,    # Default can be tuned\n    min_frequency=3,     # only after 3 times we recognize chars\n    limit_alphabet=1000, # No of alphabets\n    special_tokens=['[PAD]', '[UNK]', '[CLS]', '[MASK]', '[SEP]']\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bwpt.save(\"/kaggle/working/\", \"hindi\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cd ../input/bertsrc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"! tail -20 /kaggle/working/hindi-vocab.txt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Probability of masking a word masked_lm_prob\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!python create_pretraining_data.py \\\n    --input_file=/kaggle/input/hindi-oscar-corpus/hi_dedup_1000.txt \\\n    --output_file=/kaggle/working/tf_examples.tfrecord \\\n    --vocab_file=/kaggle/working/hindi-vocab.txt \\\n    --do_lower_case=True \\\n    --max_seq_length=128 \\\n    --max_predictions_per_seq=20 \\\n    --masked_lm_prob=0.15 \\\n    --random_seed=42 \\\n    --dupe_factor=5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# To train on TPU you need to keep them on GCP bucket","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# !python run_pretraining.py \\\n#     --input_file=gs://tf-lang-model/*.tfrecord \\\n#     --output_dir=gs://tf-lang-model/model/ \\\n#     --do_train=True \\\n#     --do_eval=True \\\n#     --bert_config_file=/kaggle/input/bert-base-uncased/config.json \\\n#     --train_batch_size=32 \\\n#     --max_seq_length=128 \\\n#     --max_predictions_per_seq=20 \\\n#     --num_train_steps=20 \\\n#     --num_warmup_steps=10 \\\n#     --learning_rate=2e-5 \\\n#     --use_tpu=True \\\n#     --tpu_name=$TPU_NAME","execution_count":18,"outputs":[{"output_type":"stream","text":"W0512 13:38:42.043282 140669911852416 module_wrapper.py:139] From run_pretraining.py:407: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n\nW0512 13:38:42.043545 140669911852416 module_wrapper.py:139] From run_pretraining.py:407: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n\nW0512 13:38:42.043859 140669911852416 module_wrapper.py:139] From /kaggle/input/bertsrc/modeling.py:93: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n\nW0512 13:38:42.045854 140669911852416 module_wrapper.py:139] From run_pretraining.py:414: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n\n2020-05-12 13:38:42.046216: W tensorflow/core/platform/cloud/google_auth_provider.cc:178] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with \"Not found: Could not locate the credentials file.\". Retrieving token from GCE failed with \"Cancelled: GCE check skipped due to presence of $NO_GCE_CHECK environment variable.\".\nTraceback (most recent call last):\n  File \"run_pretraining.py\", line 493, in <module>\n    tf.app.run()\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/platform/app.py\", line 40, in run\n    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n  File \"/opt/conda/lib/python3.6/site-packages/absl/app.py\", line 299, in run\n    _run_main(main, args)\n  File \"/opt/conda/lib/python3.6/site-packages/absl/app.py\", line 250, in _run_main\n    sys.exit(main(argv))\n  File \"run_pretraining.py\", line 414, in main\n    tf.gfile.MakeDirs(FLAGS.output_dir)\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/lib/io/file_io.py\", line 438, in recursive_create_dir\n    recursive_create_dir_v2(dirname)\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/lib/io/file_io.py\", line 453, in recursive_create_dir_v2\n    pywrap_tensorflow.RecursivelyCreateDir(compat.as_bytes(path))\ntensorflow.python.framework.errors_impl.PermissionDeniedError: Error executing an HTTP request: HTTP response code 401 with body '{\n  \"error\": {\n    \"code\": 401,\n    \"message\": \"Anonymous caller does not have storage.objects.get access to the Google Cloud Storage object.\",\n    \"errors\": [\n      {\n        \"message\": \"Anonymous caller does not have storage.objects.get access to the Google Cloud Storage object.\",\n        \"domain\": \"global\",\n        \"reason\": \"required\",\n        \"locationType\": \"header\",\n        \"location\": \"Authorization\"\n      }\n    ]\n  }\n}\n'\n\t when reading metadata of gs://tf-lang-model/model/\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"! echo $TPU_NAME","execution_count":17,"outputs":[{"output_type":"stream","text":"grpc://10.0.0.2:8470\r\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}