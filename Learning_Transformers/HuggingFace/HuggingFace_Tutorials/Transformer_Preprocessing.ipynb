{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transformer_Preprocessing.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xluArzGawbc",
        "colab_type": "text"
      },
      "source": [
        "# How to preprocess data for Transformers ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4leLmUxbAgw",
        "colab_type": "text"
      },
      "source": [
        "Every model is different yet bears similarities with the others. Therefore most models use the same inputs, which are detailed here alongside usage examples."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBFzZUWqbDCZ",
        "colab_type": "text"
      },
      "source": [
        "## Input IDs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXIhlp68bFt2",
        "colab_type": "text"
      },
      "source": [
        "The input ids are often the only required parameters to be passed to the model as input. \n",
        "\n",
        "They are token indices, numerical representations of tokens building the sequences that will be used as input by the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MLzpVVXLbhCx",
        "colab_type": "text"
      },
      "source": [
        "Each tokenizer works differently but the underlying mechanism remains the same. Here’s an example using the BERT tokenizer, which is a WordPiece tokenizer:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWQdybehardU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! pip install -q transformers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCyy648zbm74",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import BertTokenizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMR1hRIQbtSc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")\n",
        "sequence = \"A Titan RTX has 24GB of VRAM\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lu2-iy4Kb3Gg",
        "colab_type": "text"
      },
      "source": [
        "The tokenizer takes care of splitting the sequence into tokens available in the tokenizer vocabulary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93jiH7T5bzQ7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "94ba26b1-5589-4728-a7c8-d3dc7396a853"
      },
      "source": [
        "# Continuation of the previous script\n",
        "tokenized_sequence = tokenizer.tokenize(sequence)\n",
        "print(tokenized_sequence)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['A', 'Titan', 'R', '##T', '##X', 'has', '24', '##GB', 'of', 'V', '##RA', '##M']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rk4dd-WkcELf",
        "colab_type": "text"
      },
      "source": [
        "These tokens can then be converted into IDs which are understandable by the model. \n",
        "\n",
        "Several methods are available for this, the recommended being encode or encode_plus, which leverage the Rust implementation of huggingface/tokenizers for peak performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iq2u4uFRcGiI",
        "colab_type": "text"
      },
      "source": [
        "## Attention Mask"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pg5RovfcLqh",
        "colab_type": "text"
      },
      "source": [
        "The attention mask is an optional argument used when batching sequences together. \n",
        "\n",
        "This argument indicates to the model which tokens should be attended to, and which should not.\n",
        "\n",
        "For example, consider these two sequences:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2iQz2xgcBfZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yP-PTK6dcT2f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sequence_a = \"This is a short sequence.\"\n",
        "sequence_b = \"This is a rather long sequence. It is at least longer than the sequence A.\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1a-UbRYZcrFe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoded_sequence_a = tokenizer.encode(sequence_a)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4km92pgyuqK5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1d0465fb-ff6c-4e4b-930a-fef90a688a3f"
      },
      "source": [
        "print(encoded_sequence_a)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[101, 1188, 1110, 170, 1603, 4954, 119, 102]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EsIx8_Kzui47",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8c2a41b0-bed3-47ec-8239-169afae5b949"
      },
      "source": [
        "print(len(encoded_sequence_a))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYDM2FG_cvfG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoded_sequence_b = tokenizer.encode(sequence_b)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImOABC2PuiSi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "cc67ea37-c8d0-47c9-b6b5-74f372ceadf3"
      },
      "source": [
        "print(len(encoded_sequence_b))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "19\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBwdrgA5unIL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "115438ec-846d-44a1-cbf0-eaed2ed8d91b"
      },
      "source": [
        "print(encoded_sequence_b)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[101, 1188, 1110, 170, 1897, 1263, 4954, 119, 1135, 1110, 1120, 1655, 2039, 1190, 1103, 4954, 138, 119, 102]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_433HgouwiK",
        "colab_type": "text"
      },
      "source": [
        "These two sequences have different lengths and therefore can’t be put together in a same tensor as-is. The first sequence needs to be padded up to the length of the second one, or the second one needs to be truncated down to the length of the first one.\n",
        "\n",
        "In the first case, the list of IDs will be extended by the padding indices:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P2AHEUWeuzk6",
        "colab_type": "text"
      },
      "source": [
        "In the first case, the list of IDs will be extended by the padding indices:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33yNhwP4uuES",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "padded_sequence_a = tokenizer.encode(sequence_a, max_length=19, pad_to_max_length=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBe9NmCru8S4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9a2192d2-a02c-44bb-c4aa-886a3b1df28c"
      },
      "source": [
        "print(padded_sequence_a, len(padded_sequence_a))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[101, 1188, 1110, 170, 1603, 4954, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] 19\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2swvmJX0u92I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "93e9e762-c217-4378-d139-8fc041efa3e2"
      },
      "source": [
        "print(encoded_sequence_b, len(encoded_sequence_b))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[101, 1188, 1110, 170, 1897, 1263, 4954, 119, 1135, 1110, 1120, 1655, 2039, 1190, 1103, 4954, 138, 119, 102] 19\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWuPHBiLvNJ3",
        "colab_type": "text"
      },
      "source": [
        "These can then be converted into a tensor in PyTorch or TensorFlow.\n",
        "\n",
        "The attention mask is a binary tensor indicating the position of the padded indices so that the model does not attend to them. For the BertTokenizer, 1 indicate a value that should be attended to while 0 indicate a padded value."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRR7DZidvQhe",
        "colab_type": "text"
      },
      "source": [
        "The method encode_plus() may be used to obtain the attention mask directly:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzWAmhyPvZ89",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sequence_a = \"This is a short sequence.\"\n",
        "sequence_b = \"This is a rather long sequence. It is at least longer than the sequence A.\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvvcdBBXvPVH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Continuation of the previous script\n",
        "sequence_a_dict = tokenizer.encode_plus(sequence_a, max_length=19, pad_to_max_length=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIl8zocRvUhY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "60041e9e-507a-43b2-ef6e-154c3842148a"
      },
      "source": [
        "print(sequence_a_dict['input_ids'])\n",
        "print(sequence_a_dict['attention_mask'])"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[101, 1188, 1110, 170, 1603, 4954, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fAvDc6RsvrSy",
        "colab_type": "text"
      },
      "source": [
        "## Token Type IDs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvqw7AgswM9K",
        "colab_type": "text"
      },
      "source": [
        "Some models’ purpose is to do sequence classification or question answering.\n",
        "\n",
        "These require two different sequences to be encoded in the same input IDs. \n",
        "\n",
        "They are usually separated by special tokens, such as the classifier and separator tokens. For example, the BERT model builds its two sequence input as such:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yT4Ky6zvkLU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import BertTokenizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dodE4NfJwUs5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUFFuZDnwWKn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sequence_a = \"HuggingFace is based in NYC\"\n",
        "sequence_b = \"Where is HuggingFace based?\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPouZIEhwgHx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# [CLS] SEQ_A [SEP] SEQ_B [SEP]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNF6vsLfwYNv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoded_sequence = tokenizer.encode(sequence_a, sequence_b)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubY8LJaawus6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9fd99461-0d65-4d93-8d09-407550eb539c"
      },
      "source": [
        "print(encoded_sequence)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[101, 20164, 10932, 2271, 7954, 1110, 1359, 1107, 17520, 102, 2777, 1110, 20164, 10932, 2271, 7954, 1359, 136, 102]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1oV4PE34wZuv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a3b88aef-38f1-48bc-8381-d1e5fe52b343"
      },
      "source": [
        "print(tokenizer.decode(encoded_sequence))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[CLS] HuggingFace is based in NYC [SEP] Where is HuggingFace based? [SEP]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M00kUmpUwjT-",
        "colab_type": "text"
      },
      "source": [
        "This is enough for some models to understand where one sequence ends and where another begins. \n",
        "\n",
        "However, other models such as BERT have an additional mechanism, which are the segment IDs. The Token Type IDs are a binary mask identifying the different sequences in the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KxjYbvaZwnSQ",
        "colab_type": "text"
      },
      "source": [
        "We can leverage encode_plus() to output the Token Type IDs for us:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PF0XKfARwcmZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoded_dict = tokenizer.encode_plus(sequence_a, sequence_b)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DH76asolwrDm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ed2c0626-3aee-4a86-ca0d-6b413feeb35b"
      },
      "source": [
        "print(encoded_dict['input_ids'])"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[101, 20164, 10932, 2271, 7954, 1110, 1359, 1107, 17520, 102, 2777, 1110, 20164, 10932, 2271, 7954, 1359, 136, 102]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Rx6Ymzjw1WO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0df42cae-5b15-47b6-8db8-729d1a8e7acd"
      },
      "source": [
        "print(encoded_dict['token_type_ids'])"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlc_jdJAw-Dv",
        "colab_type": "text"
      },
      "source": [
        "The first sequence, the “context” used for the question, has all its tokens represented by 0, \n",
        "\n",
        "whereas the question has all its tokens represented by 1. \n",
        "\n",
        "Some models, like XLNetModel use an additional token represented by a 2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_RmMrMl0wmt",
        "colab_type": "text"
      },
      "source": [
        "# Position IDs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xa30SpZS0zb4",
        "colab_type": "text"
      },
      "source": [
        "The position IDs are used by the model to identify which token is at which position. \n",
        "\n",
        "Contrary to RNNs that have the position of each token embedded within them, transformers are unaware of the position of each token. The position IDs are created for this purpose."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WC9eXJTZ03Tn",
        "colab_type": "text"
      },
      "source": [
        "They are an optional parameter. If no position IDs are passed to the model, they are automatically created as absolute positional embeddings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mlDLli2x04pY",
        "colab_type": "text"
      },
      "source": [
        "Absolute positional embeddings are selected in the range [0, config.max_position_embeddings - 1]. \n",
        "\n",
        "Some models use other types of positional embeddings, such as sinusoidal position embeddings or relative position embeddings.\n"
      ]
    }
  ]
}